{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Part 1: Build the Friendship Network\n",
        "\n",
        "• Represent students as nodes in an undirected graph.\n",
        "• Friendships are edges with random but realistic generation logic:\n",
        "\n",
        "– Higher probability of friendship within same groups/classes\n",
        "\n",
        "– Some students are more popular (higher degree)\n",
        "\n",
        "– Friends-of-friends become more likely (clustering)\n",
        "\n",
        "• Assign weights (1–10) to represent friendship strength\n",
        "\n",
        "– Lower weight = closer connection\n",
        "\n",
        " Use an adjacency list with weights"
      ],
      "metadata": {
        "id": "EQ5_eHZDezZz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqQwBdC_eypj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from itertools import combinations\n",
        "import random\n",
        "num_people = 1000\n",
        "class_size = 50\n",
        "threshold = 0.85 #probablity above which they are friends iteratively i have updated from 0.8,0.9,0.98,0.99 to finally chose which could be optimal\n",
        "people = np.arange(num_people)\n",
        "classes = people // class_size\n",
        "\n",
        "pairs = np.array(list(combinations(people, 2)))# Generate all unique unordered pairs\n",
        "class1 = classes[pairs[:, 0]]# Identify same class or different class\n",
        "class2 = classes[pairs[:, 1]]\n",
        "same_class = class1 == class2\n",
        "\n",
        "# now let us assign probablities using random function\n",
        "probs = np.where(\n",
        "    same_class,\n",
        "    np.random.normal(0.73, 0.1, size=len(pairs)),\n",
        "    np.random.normal(0.2, 0.1, size=len(pairs))\n",
        ")\n",
        "\n",
        "# friend or not can be determined and stored in this array\n",
        "friend_flags = (probs > threshold).astype(int)\n",
        "\n",
        "# Create final_data array: [person1, person2, probability, is_friend]\n",
        "final_data = np.hstack([\n",
        "    pairs,\n",
        "    probs.reshape(-1, 1),\n",
        "    friend_flags.reshape(-1, 1)\n",
        "])\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "# let us build friend map from initial friendships\n",
        "friend_map = defaultdict(set)\n",
        "for p1, p2, _, flag in final_data:\n",
        "    if flag == 1:\n",
        "        friend_map[int(p1)].add(int(p2))\n",
        "        friend_map[int(p2)].add(int(p1))\n",
        "\n",
        "# now we can create quick pair index\n",
        "pair_index = { (min(int(p1), int(p2)), max(int(p1), int(p2))): idx for idx, (p1, p2, *_ ) in enumerate(final_data) }\n",
        "\n",
        "# Apply friend-of-friend probability boost our idea is that if they are friend of friend they will have additional probablitty than initial probablity\n",
        "for a, neighbors in friend_map.items():\n",
        "    for b, c in combinations(neighbors, 2):\n",
        "        b, c = sorted((b, c))\n",
        "        idx = pair_index.get((b, c))\n",
        "        if idx is not None and final_data[idx, 3] == 0:\n",
        "            final_data[idx, 2] += 0.1\n",
        "            final_data[idx, 2] = min(final_data[idx, 2], 1.0)\n",
        "            if final_data[idx, 2] > threshold:\n",
        "                final_data[idx, 3] = 1\n",
        "\n",
        "\n",
        "adjacency_list = [[] for _ in range(num_people)]# weighted adjacency list can be created now\n",
        "\n",
        "# we can assign weights inversely proportional to probability (1 to 10 scale)\n",
        "for p1, p2, prob, flag in final_data:\n",
        "    if flag == 1:\n",
        "        weight = int(round(10 * (1 - prob)))  # Closer friends have lower weights\n",
        "        adjacency_list[int(p1)].append((int(p2), weight))\n",
        "        adjacency_list[int(p2)].append((int(p1), weight))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2: Analyze Friend Groups\n",
        "\n",
        "• Use DFS or BFS to count connected components\n",
        "\n",
        "• Report:\n",
        "\n",
        "– Number of friend groups\n",
        "\n",
        "– Size of smallest and largest group"
      ],
      "metadata": {
        "id": "sPngE87EhTyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let us use DFS using iterative method to find connected components\n",
        "def neighbours(a, adj):\n",
        "    return [neigh for neigh, _ in adj[a]]\n",
        "\n",
        "def preorder(start, adj, marked):\n",
        "    order = []\n",
        "    stack = [start]\n",
        "    while stack:\n",
        "        a = stack.pop()\n",
        "        if not marked[a]:\n",
        "            marked[a] = 1\n",
        "            order.append(a)\n",
        "            for w in neighbours(a, adj):\n",
        "                if not marked[w]:\n",
        "                    stack.append(w)\n",
        "    return order\n",
        "\n",
        "group_no = np.zeros(num_people, dtype=int)\n",
        "group_current = 1\n",
        "\n",
        "for i in range(num_people):\n",
        "    if group_no[i] != 0:\n",
        "        continue\n",
        "    marked = [0] * num_people\n",
        "    members = preorder(i, adjacency_list, marked)\n",
        "    for m in members:\n",
        "        group_no[m] = group_current\n",
        "    group_current += 1\n",
        "total_groups = group_current - 1\n",
        "group_sizes = np.bincount(group_no.astype(int))[1:]\n",
        "\n",
        "print(\"Total number of friendship groups:\", total_groups)\n",
        "print(\"Smallest group size:\", group_sizes.min())\n",
        "print(\"Largest group size:\", group_sizes.max())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tslpz7UbhSQh",
        "outputId": "21594e3a-1172-4ebf-a5e9-28eb95c1537e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of friendship groups: 25\n",
            "Smallest group size: 1\n",
            "Largest group size: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3: Find Closest Friendship Paths\n",
        "\n",
        "• Select 5 random student pairs\n",
        "\n",
        "• Use Dijkstra’s algorithm to find shortest “friendship effort” paths\n",
        "\n",
        "• For 1 pair, also apply A* using a basic heuristic:\n",
        "\n",
        "– e.g., same class = heuristic 0, different = 5\n",
        "\n",
        "• Report paths and compare with Dijkstra\n"
      ],
      "metadata": {
        "id": "Q7yTYDeii8x6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first let us write the code for dijikistra and A* then we can implement the needed ones\n",
        "def dijkstra(start, end, adj):\n",
        "    dist = [float('inf')] * len(adj)\n",
        "    prev = [None] * len(adj)\n",
        "    visited = [False] * len(adj)\n",
        "    dist[start] = 0\n",
        "\n",
        "    nodes = list(range(len(adj)))\n",
        "\n",
        "    while nodes:\n",
        "        # Find the node with the smallest distance\n",
        "        u = min((n for n in nodes if not visited[n]), key=lambda x: dist[x], default=None)\n",
        "        if u is None or u == end:\n",
        "            break\n",
        "\n",
        "        nodes.remove(u)\n",
        "        visited[u] = True\n",
        "\n",
        "        for v, weight in adj[u]:\n",
        "            if not visited[v]:\n",
        "                alt = dist[u] + weight\n",
        "                if alt < dist[v]:\n",
        "                    dist[v] = alt\n",
        "                    prev[v] = u\n",
        "\n",
        "    # Reconstruct path\n",
        "    path = []\n",
        "    u = end\n",
        "    while u is not None:\n",
        "        path.insert(0, u)\n",
        "        u = prev[u]\n",
        "    return path, dist[end]\n",
        "\n",
        "def heuristic(u, v):\n",
        "    return 0 if (u // 50 == v // 50) else 5\n",
        "\n",
        "def a_star(start, end, adj):\n",
        "    open_set = [start]\n",
        "    came_from = [None] * len(adj)\n",
        "    g_score = [float('inf')] * len(adj)\n",
        "    f_score = [float('inf')] * len(adj)\n",
        "\n",
        "    g_score[start] = 0\n",
        "    f_score[start] = heuristic(start, end)\n",
        "\n",
        "    while open_set:\n",
        "        # Pick node with lowest f_score\n",
        "        current = min(open_set, key=lambda x: f_score[x])\n",
        "        if current == end:\n",
        "            break\n",
        "\n",
        "        open_set.remove(current)\n",
        "\n",
        "        for neighbor, weight in adj[current]:\n",
        "            tentative_g = g_score[current] + weight\n",
        "            if tentative_g < g_score[neighbor]:\n",
        "                came_from[neighbor] = current\n",
        "                g_score[neighbor] = tentative_g\n",
        "                f_score[neighbor] = tentative_g + heuristic(neighbor, end)\n",
        "                if neighbor not in open_set:\n",
        "                    open_set.append(neighbor)\n",
        "\n",
        "    # Reconstruct path\n",
        "    path = []\n",
        "    current = end\n",
        "    while current is not None:\n",
        "        path.insert(0, current)\n",
        "        current = came_from[current]\n",
        "    return path, g_score[end]\n",
        "\n",
        "# we can randomly select 5 students and then test\n",
        "random.seed(42)\n",
        "pairs_to_test = [(random.randint(0, 999), random.randint(0, 999)) for _ in range(5)]\n",
        "print(\"Random student pairs:\", pairs_to_test)\n",
        "for s, t in pairs_to_test:\n",
        "    path, cost = dijkstra(s, t, adjacency_list)\n",
        "    print(f\"Dijkstra: {s} -> {t} | Cost: {cost} | Path: {path}\")\n",
        "s, t = pairs_to_test[0]\n",
        "path, cost = a_star(s, t, adjacency_list)\n",
        "print(f\"A*: {s} -> {t} | Cost: {cost} | Path: {path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M7-9wkZjGvp",
        "outputId": "281292cb-69e1-4246-8fed-de8a2affd7a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random student pairs: [(654, 114), (25, 759), (281, 250), (228, 142), (754, 104)]\n",
            "Dijkstra: 654 -> 114 | Cost: inf | Path: [114]\n",
            "Dijkstra: 25 -> 759 | Cost: inf | Path: [759]\n",
            "Dijkstra: 281 -> 250 | Cost: inf | Path: [250]\n",
            "Dijkstra: 228 -> 142 | Cost: inf | Path: [142]\n",
            "Dijkstra: 754 -> 104 | Cost: inf | Path: [104]\n",
            "A*: 654 -> 114 | Cost: inf | Path: [114]\n"
          ]
        }
      ]
    }
  ]
}